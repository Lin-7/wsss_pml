def forward_as_dict(self, x):

    x = self.conv1a(x) # nn.Conv2d(3, 64, 3, padding=1, bias=False)  kernel:3, stride:1 感受野不变 379

    x = self.b2(x)     # ResBlock(64, 128, 128, stride=2)   187==>189==>2*(189-1)+3=2*188+3=376+3=379
    x = self.b2_1(x)   # ResBlock(128, 128, 128)  183====>187
    x = self.b2_2(x)   # ResBlock(128, 128, 128)  179====>183

    x = self.b3(x)     # ResBlock(128, 256, 256, stride=2)  87==>89==>2*(89-1)+3=179
    x = self.b3_1(x)   # ResBlock(256, 256, 256)  83====>87
    x = self.b3_2(x)   # ResBlock(256, 256, 256)  79====>83

    x = self.b4(x)     # ResBlock(256, 512, 512, stride=2)  37==》39==》2*(39-1)+3=79
    x = self.b4_1(x)   # ResBlock(512, 512, 512)  33====》37
    x = self.b4_2(x)   # ResBlock(512, 512, 512)  29====》33
    x = self.b4_3(x)   # ResBlock(512, 512, 512)  25====》29
    x = self.b4_4(x)   # ResBlock(512, 512, 512)  21====》25
    x = self.b4_5(x)   # ResBlock(512, 512, 512)  17====》21

    x, conv4 = self.b5(x, get_x_bn_relu=True)     # ResBlock(512, 512, 1024, stride=1, first_dilation=1, dilation=2)   13==》15==》17
    x = self.b5_1(x)     # ResBlock(1024, 512, 1024, dilation=2) stride=1  9==》9+2=11==》1*(11-1)+3=13
    x = self.b5_2(x)     # ResBlock(1024, 512, 1024, dilation=2) stride=1  5==》5+2=7==》1*(7-1)+3=9

    x, conv5 = self.b6(x, get_x_bn_relu=True)  # ResBlock_bot(1024, 2048, stride=1, dilation=4, dropout=0.3)    # 3==》5

    x = self.b7(x)               # ResBlock_bot(2048, 4096, dilation=4, dropout=0.5) 1==》3
    conv6 = F.relu(self.bn7(x))  # 感受野不变==》对应最后一个特征图的感受野 1

    return dict({'conv4': conv4, 'conv5': conv5, 'conv6': conv6})

ResBlock_bot
    def __init__(self, in_channels, out_channels, stride=1, dilation=1, dropout=0.):
        super(ResBlock_bot, self).__init__()

        self.same_shape = (in_channels == out_channels and stride == 1)

        self.bn_branch2a = nn.BatchNorm2d(in_channels)
        self.conv_branch2a = nn.Conv2d(in_channels, out_channels//4, 1, stride, bias=False)

        self.bn_branch2b1 = nn.BatchNorm2d(out_channels//4)
        self.dropout_2b1 = torch.nn.Dropout2d(dropout)
        self.conv_branch2b1 = nn.Conv2d(out_channels//4, out_channels//2, 3, padding=dilation, dilation=dilation, bias=False)

        self.bn_branch2b2 = nn.BatchNorm2d(out_channels//2)
        self.dropout_2b2 = torch.nn.Dropout2d(dropout)
        self.conv_branch2b2 = nn.Conv2d(out_channels//2, out_channels, 1, bias=False)

        if not self.same_shape:
            self.conv_branch1 = nn.Conv2d(in_channels, out_channels, 1, stride, bias=False)

    def forward(self, x, get_x_bn_relu=False):

        branch2 = self.bn_branch2a(x)
        branch2 = F.relu(branch2)
        x_bn_relu = branch2

        branch1 = self.conv_branch1(branch2)     # 先不考虑分支的感受野

        branch2 = self.conv_branch2a(branch2)    # 感受野不变

        branch2 = self.bn_branch2b1(branch2)     # 感受野不变
        branch2 = F.relu(branch2)                # 感受野不变
        branch2 = self.dropout_2b1(branch2)      # 感受野不变
        branch2 = self.conv_branch2b1(branch2)   # kernel:3,stride:1 感受野：1*（n-1）+3=n+2

        branch2 = self.bn_branch2b2(branch2)     # 感受野不变
        branch2 = F.relu(branch2)                # 感受野不变
        branch2 = self.dropout_2b2(branch2)      # 感受野不变
        branch2 = self.conv_branch2b2(branch2)   # kernel:1, stride:1, 感受野不变 n

        x = branch1 + branch2

        if get_x_bn_relu:
            return x, x_bn_relu

        return x


ResBlock
    def __init__(self, in_channels, mid_channels, out_channels, stride=1, first_dilation=None, dilation=1):
        super(ResBlock, self).__init__()

        self.same_shape = (in_channels == out_channels and stride == 1)

        if first_dilation == None: first_dilation = dilation

        self.bn_branch2a = nn.BatchNorm2d(in_channels)

        self.conv_branch2a = nn.Conv2d(in_channels, mid_channels, 3, stride,
                                       padding=first_dilation, dilation=first_dilation, bias=False)

        self.bn_branch2b1 = nn.BatchNorm2d(mid_channels)

        self.conv_branch2b1 = nn.Conv2d(mid_channels, out_channels, 3, padding=dilation, dilation=dilation, bias=False)

        if not self.same_shape:
            self.conv_branch1 = nn.Conv2d(in_channels, out_channels, 1, stride, bias=False)

    def forward(self, x, get_x_bn_relu=False):

        branch2 = self.bn_branch2a(x)
        branch2 = F.relu(branch2)

        x_bn_relu = branch2

        if not self.same_shape:
            branch1 = self.conv_branch1(branch2)
        else:
            branch1 = x

        branch2 = self.conv_branch2a(branch2)        # kernel:3, stride:stride  感受野：stride*（n-1）+3
        branch2 = self.bn_branch2b1(branch2)         # 感受野不变
        branch2 = F.relu(branch2)                    # 感受野不变
        branch2 = self.conv_branch2b1(branch2)       # kernel:3, stride:1  感受野：1*（n-1）+3=n+2

        x = branch1 + branch2

        if get_x_bn_relu:
            return x, x_bn_relu

        return x